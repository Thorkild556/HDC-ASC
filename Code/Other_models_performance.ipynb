{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with delta features\n",
    "import pickle\n",
    "# Load it back\n",
    "with open(\"speech_commands_mfcc_delta_features_torchaudio.pkl\", \"rb\") as f:\n",
    "    mfcc_features, labels, label_map = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "torch.Size([38546, 14, 39])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5z/ksmd9z810hv7hd63k2mmtgzr0000gn/T/ipykernel_4065/2480344048.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  mfcc_features = torch.tensor(mfcc_features, dtype=torch.float32).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([34691, 14, 39]) torch.Size([34691])\n",
      "torch.Size([3855, 14, 39]) torch.Size([3855])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from collections import OrderedDict\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "# Create a subset of 5000 signals\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "subset_size = 38546\n",
    "indices = torch.randperm(len(labels))[:subset_size]\n",
    "\n",
    "# Sort the indices\n",
    "sorted_indices = torch.sort(indices).values\n",
    "\n",
    "labels = torch.tensor(labels, dtype=torch.int32).to(device)\n",
    "mfcc_features = torch.tensor(mfcc_features, dtype=torch.float32).to(device)\n",
    "\n",
    "subset_mfcc_features = mfcc_features[sorted_indices]\n",
    "subset_labels = labels[sorted_indices]\n",
    "\n",
    "print(subset_mfcc_features.shape)\n",
    "\n",
    "\n",
    "# Define the train-test split ratio for subset\n",
    "train_ratio = 0.90\n",
    "train_size = int(train_ratio * subset_size)\n",
    "test_size = subset_size - train_size\n",
    "\n",
    "train_dataset, test_dataset = random_split(list(zip(subset_mfcc_features, subset_labels)), [train_size, test_size])\n",
    "\n",
    "\n",
    "# size = labels.shape[0]\n",
    "# # Define the train-test split ratio for full length\n",
    "# train_ratio = 0.95\n",
    "# train_size = int(train_ratio * size)\n",
    "# test_size = size - train_size\n",
    "\n",
    "\n",
    "# # Create the train-test split\n",
    "# train_dataset, test_dataset = random_split(list(zip(mfcc_features, labels)), [train_size, test_size])\n",
    "\n",
    "# Separate the features and labels for train and test sets\n",
    "train_mfcc_features, train_labels = zip(*train_dataset)\n",
    "test_mfcc_features, test_labels = zip(*test_dataset)\n",
    "\n",
    "# Convert to tensors\n",
    "train_mfcc_features = torch.stack(train_mfcc_features).to(device)\n",
    "train_labels = torch.tensor(train_labels, dtype=torch.int32).to(device)\n",
    "test_mfcc_features = torch.stack(test_mfcc_features).to(device)\n",
    "test_labels = torch.tensor(test_labels, dtype=torch.int32).to(device)\n",
    "\n",
    "print(train_mfcc_features.shape, train_labels.shape)\n",
    "print(test_mfcc_features.shape, test_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import HDcompute as hd\n",
    "import time\n",
    "vector1 = torch.tensor(hd.make_rand_vector(seed=5, size = 10000), dtype = torch.int8).to(device)\n",
    "vector2 = vector1 *-1\n",
    "\n",
    "start = time.time()\n",
    "model = hd.make_model_from_mfccs(train_mfcc_features, train_labels, vector1=vector1, vector2=vector2, \n",
    "                                  batch_size=6, device = device,\n",
    "                                  seed = 42, n_gram = 2, majority_vote=True, separate_signals= True, \n",
    "                                  alpha=1, single_window=False, weighing = True)\n",
    "end = time.time()\n",
    "print(\"model training took\", end-start,\"seconds\")\n",
    "\n",
    "start = time.time()\n",
    "preds = hd.predict(model, test_mfcc_features, majority_vote=False, weighing = True)\n",
    "end = time.time()\n",
    "print(\"prediction took\", end-start,\"seconds\")\n",
    "\n",
    "accuracy = torch.count_nonzero(preds == test_labels).item()*100/test_labels.shape[0]\n",
    "print(f\"Test Accuracy: {accuracy}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert PyTorch tensors to NumPy arrays\n",
    "train_mfcc_features_np = train_mfcc_features.cpu().numpy()\n",
    "train_labels_np = train_labels.cpu().numpy()\n",
    "test_mfcc_features_np = test_mfcc_features.cpu().numpy()\n",
    "test_labels_np = test_labels.cpu().numpy()\n",
    "\n",
    "# Reshape the features to 2D (samples, features)\n",
    "train_mfcc_features_np = train_mfcc_features_np.reshape(train_mfcc_features_np.shape[0], -1)\n",
    "test_mfcc_features_np = test_mfcc_features_np.reshape(test_mfcc_features_np.shape[0], -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "# Train the SVM\n",
    "model = SVC(kernel='rbf')\n",
    "# model = LogisticRegression(max_iter=1000)\n",
    "model.fit(train_mfcc_features_np, train_labels_np)\n",
    "end = time.time()\n",
    "print(\"model training took\", end-start,\"seconds\")\n",
    "\n",
    "start = time.time()\n",
    "# Predict on the test set\n",
    "test_predictions = model.predict(test_mfcc_features_np)\n",
    "end = time.time()\n",
    "print(\"prediction took\", end-start,\"seconds\")\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(test_labels_np, test_predictions)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Please build the library first!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mthundersvm\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mthundersvm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SVC\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/thundersvm/__init__.py:10\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m * Name        : __init__.py\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m * Author      : Locke <luojiahuan001@gmail.com>\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;03m * Version     : 0.0.1\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03m * Description :\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      9\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthundersvm\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mthundersvm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/thundersvm/thundersvm.py:52\u001b[0m\n\u001b[1;32m     50\u001b[0m         thundersvm \u001b[38;5;241m=\u001b[39m CDLL(lib_path)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease build the library first!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     53\u001b[0m SVM_TYPE \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc_svc\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnu_svc\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mone_class\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepsilon_svr\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnu_svr\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     54\u001b[0m KERNEL_TYPE \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpolynomial\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrbf\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecomputed\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Please build the library first!"
     ]
    }
   ],
   "source": [
    "import thundersvm\n",
    "from thundersvm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Assuming train and test data are prepared\n",
    "# train_mfcc_features_np, train_labels_np, test_mfcc_features_np, test_labels_np\n",
    "\n",
    "# Convert labels to integers (ThunderSVM expects numeric labels)\n",
    "train_labels_np = train_labels_np.astype(int)\n",
    "test_labels_np = test_labels_np.astype(int)\n",
    "\n",
    "# Train the SVM\n",
    "start = time.time()\n",
    "model = SVC(kernel='rbf', gpu_id=0)  # Use GPU core 0\n",
    "model.fit(train_mfcc_features_np, train_labels_np)\n",
    "end = time.time()\n",
    "print(\"Model training took\", end - start, \"seconds\")\n",
    "\n",
    "# Predict on the test set\n",
    "start = time.time()\n",
    "test_predictions = model.predict(test_mfcc_features_np)\n",
    "end = time.time()\n",
    "print(\"Prediction took\", end - start, \"seconds\")\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(test_labels_np, test_predictions)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_labels_np[0:10])\n",
    "print(test_predictions[0:10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import OrderedDict\n",
    "from torch.utils.data import random_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "for i in range(2500, 38546, 2500):\n",
    "\n",
    "    subset_size = i\n",
    "    indices = torch.randperm(len(labels))[:subset_size]\n",
    "\n",
    "    # Sort the indices\n",
    "    sorted_indices = torch.sort(indices).values\n",
    "\n",
    "    labels = torch.tensor(labels, dtype=torch.int32)\n",
    "    mfcc_features = torch.tensor(mfcc_features, dtype=torch.float32)\n",
    "\n",
    "    subset_mfcc_features = mfcc_features[sorted_indices]\n",
    "    subset_labels = labels[sorted_indices]\n",
    "\n",
    "    print(subset_mfcc_features.shape)\n",
    "\n",
    "\n",
    "    # Define the train-test split ratio for subset\n",
    "    train_ratio = 0.90\n",
    "    train_size = int(train_ratio * subset_size)\n",
    "    test_size = subset_size - train_size\n",
    "\n",
    "    train_dataset, test_dataset = random_split(list(zip(subset_mfcc_features, subset_labels)), [train_size, test_size])\n",
    "\n",
    "\n",
    "    # size = labels.shape[0]\n",
    "    # # Define the train-test split ratio for full length\n",
    "    # train_ratio = 0.95\n",
    "    # train_size = int(train_ratio * size)\n",
    "    # test_size = size - train_size\n",
    "\n",
    "\n",
    "    # # Create the train-test split\n",
    "    # train_dataset, test_dataset = random_split(list(zip(mfcc_features, labels)), [train_size, test_size])\n",
    "\n",
    "    # Separate the features and labels for train and test sets\n",
    "    train_mfcc_features, train_labels = zip(*train_dataset)\n",
    "    test_mfcc_features, test_labels = zip(*test_dataset)\n",
    "\n",
    "    # Convert to tensors\n",
    "    train_mfcc_features = torch.stack(train_mfcc_features)\n",
    "    train_labels = torch.tensor(train_labels, dtype=torch.int32)\n",
    "    test_mfcc_features = torch.stack(test_mfcc_features)\n",
    "    test_labels = torch.tensor(test_labels, dtype=torch.int32)\n",
    "\n",
    "    print(train_mfcc_features.shape, train_labels.shape)\n",
    "    print(test_mfcc_features.shape, test_labels.shape)\n",
    "\n",
    "\n",
    "    # Convert to tensors\n",
    "    # Convert PyTorch tensors to NumPy arrays\n",
    "    train_mfcc_features_np = train_mfcc_features.numpy()\n",
    "    train_labels_np = train_labels.numpy()\n",
    "    test_mfcc_features_np = test_mfcc_features.numpy()\n",
    "    test_labels_np = test_labels.numpy()\n",
    "\n",
    "\n",
    "\n",
    "    # Reshape the features to 2D (samples, features)\n",
    "    train_mfcc_features_np = train_mfcc_features_np.reshape(train_mfcc_features_np.shape[0], -1)\n",
    "    test_mfcc_features_np = test_mfcc_features_np.reshape(test_mfcc_features_np.shape[0], -1)\n",
    "\n",
    "    # Train the SVM\n",
    "    model = SVC(kernel='rbf')\n",
    "    # model = LogisticRegression(max_iter=1000)\n",
    "    model.fit(train_mfcc_features_np, train_labels_np)\n",
    "    # Predict on the test set\n",
    "    test_predictions = model.predict(test_mfcc_features_np)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(test_labels_np, test_predictions)\n",
    "    print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "    accuracies.append(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(accuracies, columns=[\"Accuracy\"])\n",
    "df.to_csv(\"SVM_accuracies.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import OrderedDict\n",
    "from torch.utils.data import random_split\n",
    "import HDcompute as hd\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "\n",
    "vector1 = torch.tensor(hd.make_rand_vector(seed=3, size = 10000), dtype = torch.int8).to(device)\n",
    "vector2 = vector1 * -1\n",
    "\n",
    "hd_accuracies = []\n",
    "\n",
    "\n",
    "for i in range(2500, 38546, 2500):\n",
    "\n",
    "    subset_size = i\n",
    "    indices = torch.randperm(len(labels))[:subset_size]\n",
    "\n",
    "    # Sort the indices\n",
    "    sorted_indices = torch.sort(indices).values\n",
    "\n",
    "    labels = torch.tensor(labels, dtype=torch.int32)\n",
    "    mfcc_features = torch.tensor(mfcc_features, dtype=torch.float32)\n",
    "\n",
    "    subset_mfcc_features = mfcc_features[sorted_indices]\n",
    "    subset_labels = labels[sorted_indices]\n",
    "\n",
    "    print(subset_mfcc_features.shape)\n",
    "\n",
    "\n",
    "    # Define the train-test split ratio for subset\n",
    "    train_ratio = 0.90\n",
    "    train_size = int(train_ratio * subset_size)\n",
    "    test_size = subset_size - train_size\n",
    "\n",
    "    train_dataset, test_dataset = random_split(list(zip(subset_mfcc_features, subset_labels)), [train_size, test_size])\n",
    "\n",
    "    # Separate the features and labels for train and test sets\n",
    "    train_mfcc_features, train_labels = zip(*train_dataset)\n",
    "    test_mfcc_features, test_labels = zip(*test_dataset)\n",
    "\n",
    "    # Convert to tensors\n",
    "    train_mfcc_features = torch.stack(train_mfcc_features).to(device)\n",
    "    train_labels = torch.tensor(train_labels, dtype=torch.int32).to(device)\n",
    "    test_mfcc_features = torch.stack(test_mfcc_features).to(device)\n",
    "    test_labels = torch.tensor(test_labels, dtype=torch.int32).to(device)\n",
    "\n",
    "\n",
    "    print(train_mfcc_features.shape, train_labels.shape)\n",
    "    print(test_mfcc_features.shape, test_labels.shape)\n",
    "\n",
    "    model = hd.make_model_from_mfccs(train_mfcc_features, train_labels, vector1=vector1, vector2=vector2, \n",
    "                                  batch_size=4, device = device,\n",
    "                                  seed = 42, n_gram = 2, majority_vote=True, separate_signals= True, \n",
    "                                  alpha=1, single_window=False, weighing = True)\n",
    "\n",
    "    preds = hd.predict(model, test_mfcc_features, majority_vote=False, weighing = True)\n",
    "\n",
    "    accuracy = torch.count_nonzero(preds == test_labels).item()*100/test_labels.shape[0]\n",
    "\n",
    "    print(f\"Test Accuracy: {accuracy}%\")\n",
    "\n",
    "    hd_accuracies.append(accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example numpy arrays (replace with your actual data)\n",
    "accuracies_np = np.asanyarray( hd_accuracies)  # Replace with your predictions array\n",
    "\n",
    "\n",
    "# Save to CSV\n",
    "np.savetxt(\"HD_accuracies.csv\", accuracies_np, delimiter=\",\", header=\"Accuracy\", comments=\"\",  fmt=\"%.2f\")\n",
    "\n",
    "print(\"CSV file saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n",
      "size: 2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5z/ksmd9z810hv7hd63k2mmtgzr0000gn/T/ipykernel_85318/3334103136.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels, dtype=torch.int32)\n",
      "/var/folders/5z/ksmd9z810hv7hd63k2mmtgzr0000gn/T/ipykernel_85318/3334103136.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  mfcc_features = torch.tensor(mfcc_features, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 74.0%\n",
      "size: 5000\n",
      "Test Accuracy: 76.9%\n",
      "size: 7500\n",
      "Test Accuracy: 76.7%\n",
      "size: 10000\n",
      "Test Accuracy: 78.2%\n",
      "size: 15000\n",
      "Test Accuracy: 77.9%\n",
      "size: 20000\n",
      "Test Accuracy: 79.1%\n",
      "size: 25000\n",
      "Test Accuracy: 78.2%\n",
      "size: 30000\n",
      "Test Accuracy: 78.7%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from collections import OrderedDict\n",
    "from torch.utils.data import random_split\n",
    "import HDcompute as hd\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "hd_accuracies_size = []\n",
    "vector_sizes = [2500, 5000, 7500, 10000, 15000, 20000, 25000, 30000] \n",
    "\n",
    "\n",
    "\n",
    "for i in vector_sizes:\n",
    "\n",
    "    vector1 = torch.tensor(hd.make_rand_vector(seed=3, size = i), dtype = torch.int8).to(device)\n",
    "    vector2 = vector1 * -1\n",
    "    print(\"size:\", i)\n",
    "\n",
    "    subset_size = 10000\n",
    "    indices = torch.randperm(len(labels))[:subset_size]\n",
    "\n",
    "\n",
    "    labels = torch.tensor(labels, dtype=torch.int32)\n",
    "    mfcc_features = torch.tensor(mfcc_features, dtype=torch.float32)\n",
    "\n",
    "    subset_mfcc_features = mfcc_features[indices]\n",
    "    subset_labels = labels[indices]\n",
    "\n",
    "\n",
    "    # Define the train-test split ratio for subset\n",
    "    train_ratio = 0.90\n",
    "    train_size = int(train_ratio * subset_size)\n",
    "    test_size = subset_size - train_size\n",
    "\n",
    "    train_dataset, test_dataset = random_split(list(zip(subset_mfcc_features, subset_labels)), [train_size, test_size])\n",
    "\n",
    "    # Separate the features and labels for train and test sets\n",
    "    train_mfcc_features, train_labels = zip(*train_dataset)\n",
    "    test_mfcc_features, test_labels = zip(*test_dataset)\n",
    "\n",
    "    # Convert to tensors\n",
    "    train_mfcc_features = torch.stack(train_mfcc_features).to(device)\n",
    "    train_labels = torch.tensor(train_labels, dtype=torch.int32).to(device)\n",
    "    test_mfcc_features = torch.stack(test_mfcc_features).to(device)\n",
    "    test_labels = torch.tensor(test_labels, dtype=torch.int32).to(device)\n",
    "\n",
    "\n",
    "    model = hd.make_model_from_mfccs(train_mfcc_features, train_labels, vector1=vector1, vector2=vector2, \n",
    "                                  batch_size=4, device = device,\n",
    "                                  seed = 8, n_gram = 2, majority_vote=True, separate_signals= True, \n",
    "                                  alpha=1, single_window=False, weighing = True)\n",
    "\n",
    "    preds = hd.predict(model, test_mfcc_features, majority_vote=False, weighing = True)\n",
    "\n",
    "    accuracy = torch.count_nonzero(preds == test_labels).item()*100/test_labels.shape[0]\n",
    "\n",
    "    print(f\"Test Accuracy: {accuracy}%\")\n",
    "\n",
    "    hd_accuracies_size.append(accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example numpy arrays (replace with your actual data)\n",
    "accuracies_size_np = np.asanyarray( hd_accuracies_size)  # Replace with your predictions array\n",
    "\n",
    "\n",
    "# Save to CSV\n",
    "np.savetxt(\"HD_accuracies_over_size.csv\", accuracies_size_np, delimiter=\",\", header=\"Accuracy\", comments=\"\",  fmt=\"%.2f\")\n",
    "\n",
    "print(\"CSV file saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracies_size_np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(accuracies_size_np)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(hd_accuracies_size)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'accuracies_size_np' is not defined"
     ]
    }
   ],
   "source": [
    "print(accuracies_size_np)\n",
    "print(hd_accuracies_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
